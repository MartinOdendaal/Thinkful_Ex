{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Build your own neural network\n",
    "\n",
    "For this challenge you have two options for how to use neural networks . Choose one of the following:\n",
    "\n",
    "Use RBM to perform feature extraction on an image-based dataset that you find or create. If you go this route, present the features you extract and explain why this is a useful feature extraction method in the context you’re operating in. DO NOT USE either the MNIST digit recognition database or the iris data set. They’ve been worked on in very public ways very very many times and the code is easily available. (However, that code could be a useful resource to refer to). OR,\n",
    "\n",
    "Create a multi-layer perceptron neural network model to predict on a labeled dataset of your choosing. Compare this model to either a boosted tree or a random forest model and describe the relative tradeoffs between complexity and accuracy. Be sure to vary the hyperparameters of your MLP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing performance of of NN in detecting credit card fraud against a random forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard = pd.read_csv('C:\\\\Users\\\\User\\\\Documents\\\\Python_scripts\\\\Thinkful\\\\creditcard.csv')\n",
    "creditcard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some adjustments to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing class imbalance\n",
    "creditcard.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Scale using RobustScale to account for outliers in Amount\n",
    "scaler = preprocessing.RobustScaler()\n",
    "norm = scaler.fit_transform(creditcard.loc[:,['Amount', 'Time']])\n",
    "norm = pd.DataFrame(norm, columns=['Amount', 'Time'])\n",
    "\n",
    "# Get data into the right shape, drop Amount, Time, Class\n",
    "credit = creditcard.loc[:, ~((creditcard.columns).isin(['Amount', 'Time', 'Class']))]\n",
    "\n",
    "# Add transformed Amount and Time for final features (X) and create outcome (Y)\n",
    "X = pd.concat([credit, norm], axis=1)\n",
    "y = creditcard['Class']\n",
    "\n",
    "# Split on X and y, stratifying on y\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    738\n",
      "1    369\n",
      "Name: y, dtype: int64\n",
      "1107\n"
     ]
    }
   ],
   "source": [
    "# Making the X_train set balanced w.r.t y\n",
    "\n",
    "# First join X_train and y_train again\n",
    "Xwithy = X_train.copy()\n",
    "Xwithy['y']=y_train\n",
    "\n",
    "# Then randomly select as 2 times as many features with y=0 as there are where y=1\n",
    "countoffrauds = Xwithy.loc[Xwithy['y']==1, 'y'].sum()\n",
    "notfrauds = Xwithy.loc[Xwithy['y']==0, :].sample(countoffrauds*2, replace=False)\n",
    "\n",
    "# Get a dataset of only y=1\n",
    "fraud = Xwithy.loc[Xwithy['y']==1,:]\n",
    "\n",
    "# Join the two datasets\n",
    "balanced = pd.concat([notfrauds, fraud])\n",
    "\n",
    "#Split out X and y again\n",
    "y_balanced = balanced['y']\n",
    "X_balanced = balanced.drop('y', axis=1)\n",
    "\n",
    "print(y_balanced.value_counts())\n",
    "print(len(X_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The incumbent: RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class      0   1\n",
      "row_0           \n",
      "0      71072  33\n",
      "1          7  90\n",
      "Accuracy is: 0.999\n",
      "Sensitivity is: 0.732\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# Initialising and fitting the model\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Testing prediction\n",
    "y_hat = rf.predict(X_test)\n",
    "\n",
    "# Assume threshold of .5\n",
    "#threshold = np.where(y_hat>0.5,1,0)\n",
    "cross = pd.crosstab(y_hat, y_test)\n",
    "print(cross)\n",
    "acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "print('Accuracy is: %0.3f' % acc)\n",
    "print('Sensitivity is: %0.3f' % sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.95      0.75      0.84       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class      0   1\n",
      "row_0           \n",
      "0      56856   3\n",
      "1          7  96\n",
      "Accuracy for fold 1 is 0.9998244443664197\n",
      "Sensitivity for fold 1 is 0.9696969696969697\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56860   4\n",
      "1          3  95\n",
      "Accuracy for fold 2 is 0.9998771110564938\n",
      "Sensitivity for fold 2 is 0.9595959595959596\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56860   4\n",
      "1          3  94\n",
      "Accuracy for fold 3 is 0.9998771088990713\n",
      "Sensitivity for fold 3 is 0.9591836734693877\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56858   8\n",
      "1          5  90\n",
      "Accuracy for fold 4 is 0.9997717736697038\n",
      "Sensitivity for fold 4 is 0.9183673469387755\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56860   6\n",
      "1          3  92\n",
      "Accuracy for fold 5 is 0.9998419971559488\n",
      "Sensitivity for fold 5 is 0.9387755102040817\n"
     ]
    }
   ],
   "source": [
    "# Try StratiefiedKFold\n",
    "count = 0\n",
    "skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True,random_state=42)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    Xs_train, Xs_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    ys_train, ys_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    rfc = ensemble.RandomForestClassifier()\n",
    "    rfc.fit(Xs_train, ys_train)\n",
    "    y_hat = rf.predict_proba(Xs_test)[:,1]\n",
    "    # Threshold of 0.3\n",
    "    threshold = np.where(y_hat>0.3,1,0)\n",
    "    cross = pd.crosstab(threshold, ys_test)\n",
    "    print(cross)\n",
    "    acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "    sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "    count += 1\n",
    "    print('Accuracy for fold {} is {}'.format(count, acc))\n",
    "    print('Sensitivity for fold {} is {}'.format(count, sensitive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenger: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.999\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      71066  26\n",
      "1         13  97\n",
      "Accuracy is: 0.999\n",
      "Sensitivity is: 0.789\n"
     ]
    }
   ],
   "source": [
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model.\n",
    "# Reduce iterations to 200\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(28,), max_iter=200)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: %0.3f\" % mlp.score(X_train, y_train))\n",
    "\n",
    "#Fit to test\n",
    "y_hat = mlp.predict(X_test)\n",
    "\n",
    "cross = pd.crosstab(y_hat, y_test)\n",
    "print(cross)\n",
    "acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "print('Accuracy is: %0.3f' % acc)\n",
    "print('Sensitivity is: %0.3f' % sensitive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing. First attempt and the NN performs better in terms of accuracy and sensitivity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.88      0.79      0.83       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      71069  27\n",
      "1         10  96\n",
      "Accuracy is: 0.999\n",
      "Sensitivity is: 0.780\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.91      0.78      0.84       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Establish and fit the model.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(29,), max_iter=200)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: %0.3f\" % mlp.score(X_train, y_train))\n",
    "\n",
    "#Fit to test\n",
    "y_hat = mlp.predict(X_test)\n",
    "\n",
    "cross = pd.crosstab(y_hat, y_test)\n",
    "print(cross)\n",
    "acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "print('Accuracy is: %0.3f' % acc)\n",
    "print('Sensitivity is: %0.3f' % sensitive)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class      0   1\n",
      "row_0           \n",
      "0      56855  20\n",
      "1          8  79\n",
      "Accuracy for fold 1 is 0.9995084442259752\n",
      "Sensitivity for fold 1 is 0.797979797979798\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56853  21\n",
      "1         10  78\n",
      "Accuracy for fold 2 is 0.9994557775359011\n",
      "Sensitivity for fold 2 is 0.7878787878787878\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56857  24\n",
      "1          6  74\n",
      "Accuracy for fold 3 is 0.9994733238531627\n",
      "Sensitivity for fold 3 is 0.7551020408163265\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56856  26\n",
      "1          7  72\n",
      "Accuracy for fold 4 is 0.999420656238479\n",
      "Sensitivity for fold 4 is 0.7346938775510204\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      56851  17\n",
      "1         12  81\n",
      "Accuracy for fold 5 is 0.999490879724724\n",
      "Sensitivity for fold 5 is 0.826530612244898\n"
     ]
    }
   ],
   "source": [
    "# Okay, but how does it do in CV\n",
    "\n",
    "# Try StratiefiedKFold\n",
    "count = 0\n",
    "skf = model_selection.StratifiedKFold(n_splits=5, shuffle=True,random_state=42)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    Xs_train, Xs_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    ys_train, ys_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(29,), max_iter=200)\n",
    "    mlp.fit(Xs_train, ys_train)\n",
    "    y_hat = mlp.predict(Xs_test)\n",
    "    cross = pd.crosstab(y_hat, ys_test)\n",
    "    print(cross)\n",
    "    acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "    sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "    count += 1\n",
    "    print('Accuracy for fold {} is {}'.format(count, acc))\n",
    "    print('Sensitivity for fold {} is {}'.format(count, sensitive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the NN does better, but in CV the sensitivity performs worse (but is still consistent so no overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      71068  25\n",
      "1         11  98\n",
      "Accuracy is: 0.999\n",
      "Sensitivity is: 0.797\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.90      0.80      0.84       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding a second layers\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(29,14), max_iter=200)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: %0.3f\" % mlp.score(X_train, y_train))\n",
    "\n",
    "#Fit to test\n",
    "y_hat = mlp.predict(X_test)\n",
    "\n",
    "cross = pd.crosstab(y_hat, y_test)\n",
    "print(cross)\n",
    "acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "print('Accuracy is: %0.3f' % acc)\n",
    "print('Sensitivity is: %0.3f' % sensitive)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.000\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      71069  28\n",
      "1         10  95\n",
      "Accuracy is: 0.999\n",
      "Sensitivity is: 0.772\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.90      0.77      0.83       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding a third layer\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(29,14,7), max_iter=200)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: %0.3f\" % mlp.score(X_train, y_train))\n",
    "\n",
    "#Fit to test\n",
    "y_hat = mlp.predict(X_test)\n",
    "\n",
    "cross = pd.crosstab(y_hat, y_test)\n",
    "print(cross)\n",
    "acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "print('Accuracy is: %0.3f' % acc)\n",
    "print('Sensitivity is: %0.3f' % sensitive)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.999\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      71064  28\n",
      "1         15  95\n",
      "Accuracy is: 0.999\n",
      "Sensitivity is: 0.772\n"
     ]
    }
   ],
   "source": [
    "# Establish and fit the model.\n",
    "# Reduce iterations to 200\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(28,), max_iter=200, activation='logistic')\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: %0.3f\" % mlp.score(X_train, y_train))\n",
    "\n",
    "#Fit to test\n",
    "y_hat = mlp.predict(X_test)\n",
    "\n",
    "cross = pd.crosstab(y_hat, y_test)\n",
    "print(cross)\n",
    "acc = (cross[0][0]+cross[1][1])/len(y_hat)\n",
    "sensitive = cross[1][1]/(cross[1][0]+cross[1][1])\n",
    "print('Accuracy is: %0.3f' % acc)\n",
    "print('Sensitivity is: %0.3f' % sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=400, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "Accuracy is: 1.000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e0b8d9fe450e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m print(metrics.classification_report(y_test, y_hat,\n\u001b[1;32m---> 22\u001b[1;33m                                     target_names=dataset_test.target_names))\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mcross\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_test' is not defined"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes':[(29,), (50,)],\n",
    "          'max_iter': [200, 400],\n",
    "          #'activation': ['logistic', 'relu'],\n",
    "          #'solver' : ['sgd', 'adam']\n",
    "         }\n",
    "\n",
    "# Initialize the model\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Apply GridSearch to the model\n",
    "grid = model_selection.GridSearchCV(mlp, params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Save model for use in CV\n",
    "sv_best = grid.best_estimator_\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "print(\"Accuracy is: %0.3f\" % grid.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.92      0.78      0.85       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n",
      "Class      0   1\n",
      "row_0           \n",
      "0      71071  27\n",
      "1          8  96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_hat = grid.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_hat))\n",
    "cross = pd.crosstab(y_hat, y_test)\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
